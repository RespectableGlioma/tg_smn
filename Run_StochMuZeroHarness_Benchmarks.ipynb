{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Run Stochastic MuZero Harness Benchmarks (Othello + 2048)\nThis notebook clones the repo from GitHub and runs:\n- training on **Othello**\n- training on **2048**\n- evaluation for each\n- optional MCTS planning eval on 2048\n\nOutputs (checkpoints + rollout PNGs) are saved to Google Drive."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "!nvidia-smi -L || true\nimport torch, sys\nprint('torch', torch.__version__, 'cuda available?', torch.cuda.is_available())",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from google.colab import drive\ndrive.mount('/content/drive')",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import os, pathlib\nROOT = '/content/drive/MyDrive/Colab_Notebooks'\nREPO_DIR = f'{ROOT}/tg_smn'\nOUTROOT = f'{ROOT}/tg_smn_outputs_stoch_muzero'\nBRANCH = ''  # optionally set to 'stoch-muzero-harness' if you pushed a branch and haven't merged yet\n\npathlib.Path(ROOT).mkdir(parents=True, exist_ok=True)\npathlib.Path(OUTROOT).mkdir(parents=True, exist_ok=True)\nprint('ROOT:', ROOT)\nprint('REPO_DIR:', REPO_DIR)\nprint('OUTROOT:', OUTROOT)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%%bash\nset -e\nROOT=/content/drive/MyDrive/Colab_Notebooks\ncd $ROOT\nif [ ! -d tg_smn ]; then\n  git clone https://github.com/RespectableGlioma/tg_smn.git\nfi\ncd tg_smn\ngit fetch --all\nif [ -n \"${BRANCH}\" ]; then\n  git checkout ${BRANCH}\nelse\n  git checkout $(git symbolic-ref --short HEAD)\nfi\ngit pull\ngit status",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "!pip -q install -U pip setuptools wheel\n!pip -q install tqdm pillow numpy\n# (torch is preinstalled on Colab; no need to pip install torch unless you want a specific build)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Quick import test"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%cd $REPO_DIR\nimport world_models.stoch_muzero_harness as smh\nprint('Imported:', smh.__name__)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Train: Othello"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%cd $REPO_DIR\nGAME='othello'\n!python -u -m world_models.stoch_muzero_harness.train \\\n  --game $GAME \\\n  --collect_episodes 300 \\\n  --train_steps 20000 \\\n  --eval_every 2000 \\\n  --save_every 5000 \\\n  --device cuda \\\n  --outdir \"$OUTROOT\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Eval: Othello (prediction-only)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%cd $REPO_DIR\n!python -u -m world_models.stoch_muzero_harness.eval \\\n  --game othello \\\n  --ckpt \"$OUTROOT/othello/ckpt_final.pt\" \\\n  --episodes 50 \\\n  --device cuda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Train: 2048"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%cd $REPO_DIR\nGAME='2048'\n!python -u -m world_models.stoch_muzero_harness.train \\\n  --game $GAME \\\n  --collect_episodes 300 \\\n  --train_steps 20000 \\\n  --eval_every 2000 \\\n  --save_every 5000 \\\n  --device cuda \\\n  --outdir \"$OUTROOT\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Eval: 2048 (prediction-only)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%cd $REPO_DIR\n!python -u -m world_models.stoch_muzero_harness.eval \\\n  --game 2048 \\\n  --ckpt \"$OUTROOT/2048/ckpt_final.pt\" \\\n  --episodes 50 \\\n  --device cuda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Eval: 2048 with MCTS planning (optional)\nThis uses the learned latent model for search and applies the entropy shortcut:\n- low entropy chance \u2192 deterministic rollout\n- high entropy chance \u2192 sample outcomes"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "%cd $REPO_DIR\n!python -u -m world_models.stoch_muzero_harness.eval \\\n  --game 2048 \\\n  --ckpt \"$OUTROOT/2048/ckpt_final.pt\" \\\n  --episodes 50 \\\n  --mcts_sims 64 \\\n  --entropy_thr 0.5 \\\n  --device cuda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## View latest rollout images"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\ndef show_latest(pattern, title):\n    paths = sorted(glob.glob(pattern))\n    if not paths:\n        print('No images found for', pattern)\n        return\n    p = paths[-1]\n    print(title, '->', p)\n    img = Image.open(p)\n    plt.figure(figsize=(14, 4))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    plt.show()\n\nshow_latest(f'{OUTROOT}/othello/rollout_gt_vs_pred_step*.png', 'Othello rollout')\nshow_latest(f'{OUTROOT}/2048/rollout_gt_vs_pred_step*.png', '2048 rollout')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Run_StochMuZeroHarness_Benchmarks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}