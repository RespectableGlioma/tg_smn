{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TG-SMN Runner\n",
    "\n",
    "This notebook is the **top-level interface** for running TG-SMN experiments.\n",
    "\n",
    "It uses the `tg_smn` Python package in this repo to:\n",
    "- build environments (WT2 permuted-vocab; multi-domain continual LM)\n",
    "- run baselines and TG-SMN variants\n",
    "- run expert-count + seed sweeps\n",
    "- load + visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install (Colab/GitHub-friendly)\n",
    "#\n",
    "# This cell tries to locate the repo root (where `pyproject.toml` and `tg_smn/` live),\n",
    "# `cd` into it, and install the package editable.\n",
    "\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_repo_root(max_depth: int = 4) -> str | None:\n",
    "    # 1) Walk up from CWD\n",
    "    p = Path.cwd().resolve()\n",
    "    for _ in range(6):\n",
    "        if (p / 'pyproject.toml').exists() and (p / 'tg_smn').is_dir():\n",
    "            return str(p)\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "\n",
    "    # 2) Search common Colab locations (shallow)\n",
    "    for base in [Path('/content'), Path('/content/drive')]:\n",
    "        if not base.exists():\n",
    "            continue\n",
    "        for root, dirs, files in os.walk(base):\n",
    "            try:\n",
    "                rel = Path(root).relative_to(base)\n",
    "                if len(rel.parts) > max_depth:\n",
    "                    dirs[:] = []\n",
    "                    continue\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if 'pyproject.toml' in files and 'tg_smn' in dirs:\n",
    "                return root\n",
    "\n",
    "    return None\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "if REPO_ROOT is None:\n",
    "    raise RuntimeError(\n",
    "        'Could not find repo root. If you cloned the repo, run: %cd /content/<repo> and re-run this cell.'\n",
    "    )\n",
    "\n",
    "os.chdir(REPO_ROOT)\n",
    "print('Repo root:', REPO_ROOT)\n",
    "\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', '-e', '.'])\n",
    "print('Installed tg-smn editable.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tg_smn.config import (\n",
    "    DataCfg, TrainCfgLM, ModelCfgLM, FixedCtrlCfg, LearnedCtrlCfgLM,\n",
    "    WT2EnvCfg, MultiDomainEnvCfg,\n",
    ")\n",
    "from tg_smn.sweep import run_grid, LearnedAblation\n",
    "from tg_smn.analysis import load_grid_results, plot_scaling\n",
    "\n",
    "print('OK: imported tg_smn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output directory\n",
    "\n",
    "In Colab, you probably want this under Google Drive:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "OUT_ROOT = '/content/drive/MyDrive/tg_smn_runs'\n",
    "```\n",
    "\n",
    "If you don't want Drive, just use a local folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your preferred location\n",
    "OUT_ROOT = os.path.expanduser('~/tg_smn_runs')\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "print('OUT_ROOT =', OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose environments\n",
    "\n",
    "### 1) WT2 permuted-vocab\n",
    "A strong adversarial continual-learning environment.\n",
    "\n",
    "### 2) Multi-domain continual LM\n",
    "A harder, more realistic environment: WT2 / PTB / AGNews / IMDb with domain shifts (and optional domain mixing per task).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = [\n",
    "    WT2EnvCfg(name='wt2_perm_unique_10', n_tasks=10, permuted_vocab=True, perm_mode='unique'),\n",
    "    MultiDomainEnvCfg(name='md_rr_40', n_tasks=40, schedule_mode='round_robin', mix_n_domains_per_task=1),\n",
    "    # Harder: mixed-domain tasks\n",
    "    MultiDomainEnvCfg(name='md_rr_mix2_40', n_tasks=40, schedule_mode='round_robin', mix_n_domains_per_task=2, mix_seed=0),\n",
    "]\n",
    "\n",
    "envs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep configuration\n",
    "\n",
    "Start small for a smoke test, then scale up experts + seeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared configs\n",
    "data_cfg  = DataCfg(seq_len=64, batch_size=32, num_workers=2)\n",
    "train_cfg = TrainCfgLM(epochs_per_task=1, lr=3e-4, fisher_every=100, delta_rho_samples=3, log_every=20, max_steps_per_task=75)\n",
    "model_cfg = ModelCfgLM(d_model=192, n_heads=4, n_layers=4, dropout=0.1, n_experts=256, rank=16, max_k=2, group_size=32)\n",
    "fixed_ctrl_cfg = FixedCtrlCfg(k=2, replay_ratio=0.10, router_noise=0.30, router_temp=1.0)\n",
    "learned_ctrl_cfg = LearnedCtrlCfgLM(k_min=1, k_max=2, replay_max=0.5, noise_max=0.5, temp_min=0.7, temp_max=1.3)\n",
    "\n",
    "experts = [256, 512]\n",
    "seeds   = [0, 1]\n",
    "\n",
    "ablations = [\n",
    "    LearnedAblation(name='none'),\n",
    "    LearnedAblation(name='fix_k2', fixed_k=2),\n",
    "    LearnedAblation(name='fix_replay0.1', fixed_replay=0.10),\n",
    "    LearnedAblation(name='drop_obs_kl', drop_obs_kl=True),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_grid(\n",
    "    env_cfgs=envs,\n",
    "    experts_list=experts,\n",
    "    seeds=seeds,\n",
    "    out_root=OUT_ROOT,\n",
    "    variants=('dense_baseline','sparse_fixed','tg_smn_learned'),\n",
    "    data_cfg=data_cfg,\n",
    "    model_cfg=model_cfg,\n",
    "    train_cfg=train_cfg,\n",
    "    fixed_ctrl_cfg=fixed_ctrl_cfg,\n",
    "    learned_ctrl_cfg=learned_ctrl_cfg,\n",
    "    learned_ablations=ablations[1:],\n",
    "    skip_existing=True,\n",
    ")\n",
    "df.sort_values(['env','variant','ablation','n_experts','seed']).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize scaling\n",
    "\n",
    "These plots use `grid_results.csv` under `OUT_ROOT`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = load_grid_results(OUT_ROOT)\n",
    "print('rows:', len(df2))\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an environment name from df2['env'].unique()\n",
    "env_name = df2['env'].unique()[0]\n",
    "print('env_name =', env_name)\n",
    "\n",
    "plot_scaling(df2, env=env_name, metric='final_test_ppl', ablation='none')\n",
    "plot_scaling(df2, env=env_name, metric='avg_forgetting_ppl', ablation='none')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}