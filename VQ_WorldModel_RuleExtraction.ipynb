{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# VQ-VAE World Model: Learning Rules from Pixels\n",
        "\n",
        "This notebook runs the VQ-VAE world model experiments that learn to:\n",
        "1. **Distinguish deterministic rules from stochastic chance** (without being told!)\n",
        "2. **Extract interpretable rules** from the learned representations\n",
        "\n",
        "## Key Insight\n",
        "\n",
        "VQ-VAE with categorical transition predictions = **entropy learned from data**:\n",
        "- Same (code, action) → same next_code consistently = **RULE** (low entropy)\n",
        "- Same (code, action) → varied next_codes = **CHANCE** (high entropy)\n",
        "\n",
        "## Experiments\n",
        "\n",
        "1. **2048**: Should show ~14x higher entropy for positions that change (stochastic tile spawns)\n",
        "2. **Othello**: Should show near-zero entropy everywhere (fully deterministic)\n",
        "3. **Rule Extraction**: Visualize what the model learned as interpretable rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_check"
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi -L || echo 'No GPU detected'\n",
        "import torch\n",
        "print(f'PyTorch {torch.__version__}, CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "import os, sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    REPO_DIR = '/content/drive/MyDrive/Colab_Notebooks/tg_smn'\n",
        "    OUT_DIR = '/content/drive/MyDrive/Colab_Notebooks/vq_world_model_outputs'\n",
        "else:\n",
        "    REPO_DIR = os.getcwd()\n",
        "    OUT_DIR = os.path.join(REPO_DIR, 'outputs')\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print(f'REPO_DIR: {REPO_DIR}')\n",
        "print(f'OUT_DIR: {OUT_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone or update repo\n",
        "import pathlib\n",
        "\n",
        "if IN_COLAB:\n",
        "    parent = pathlib.Path(REPO_DIR).parent\n",
        "    parent.mkdir(parents=True, exist_ok=True)\n",
        "    %cd {parent}\n",
        "\n",
        "    if not os.path.exists(REPO_DIR):\n",
        "        !git clone https://github.com/RespectableGlioma/tg_smn.git\n",
        "    else:\n",
        "        %cd {REPO_DIR}\n",
        "        !git pull\n",
        "\n",
        "%cd {REPO_DIR}\n",
        "!ls -la world_models/stoch_muzero/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q tqdm numpy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment1_header"
      },
      "source": [
        "---\n",
        "## Experiment 1: 2048 (Stochastic Game)\n",
        "\n",
        "2048 has:\n",
        "- **Deterministic** slide/merge mechanics (THE RULES)\n",
        "- **Stochastic** tile spawns (THE CHANCE)\n",
        "\n",
        "The model should learn BOTH - showing bimodal entropy distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_2048"
      },
      "outputs": [],
      "source": [
        "# Train VQ World Model on 2048\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "!python -m world_models.stoch_muzero.train_vq_v2 \\\n",
        "    --game 2048 \\\n",
        "    --train_steps 20000 \\\n",
        "    --batch_size 32 \\\n",
        "    --codebook_size 512 \\\n",
        "    --n_trajectories 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment2_header"
      },
      "source": [
        "---\n",
        "## Experiment 2: Othello (Deterministic Game)\n",
        "\n",
        "Othello has:\n",
        "- **Only deterministic** transitions\n",
        "- No randomness at all\n",
        "\n",
        "The model should show near-zero entropy EVERYWHERE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_othello"
      },
      "outputs": [],
      "source": [
        "# Train VQ World Model on Othello\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "!python -m world_models.stoch_muzero.train_vq_v2 \\\n",
        "    --game othello \\\n",
        "    --train_steps 20000 \\\n",
        "    --batch_size 32 \\\n",
        "    --codebook_size 512 \\\n",
        "    --n_trajectories 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rule_extraction_header"
      },
      "source": [
        "---\n",
        "## Rule Extraction & Visualization\n",
        "\n",
        "Now we extract and visualize what the models learned:\n",
        "1. **Codebook Gallery**: What does each discrete code represent?\n",
        "2. **Entropy Distribution**: How many rules vs chance transitions?\n",
        "3. **Transition Graph**: Visual map of the learned dynamics\n",
        "4. **Rule Summary**: List of discovered deterministic rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rule_extraction_setup"
      },
      "outputs": [],
      "source": [
        "# Setup for rule extraction\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import our modules\n",
        "import sys\n",
        "sys.path.insert(0, REPO_DIR)\n",
        "\n",
        "from world_models.stoch_muzero.vq_model_v2 import VQWorldModel, VQWorldModelConfig\n",
        "from world_models.stoch_muzero.rule_extraction import RuleExtractor, analyze_model\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_data_for_analysis"
      },
      "outputs": [],
      "source": [
        "# Generate fresh data for analysis\n",
        "from world_models.stoch_muzero.train_vq_v2 import generate_trajectories\n",
        "\n",
        "print(\"Generating 2048 data for analysis...\")\n",
        "obs_2048, actions_2048 = generate_trajectories('2048', n_trajectories=500, max_steps=30, img_size=64)\n",
        "obs_2048_t = torch.from_numpy(obs_2048).to(device)\n",
        "actions_2048_t = torch.from_numpy(actions_2048).to(device)\n",
        "print(f\"  2048: {obs_2048.shape[0]} trajectories, {obs_2048.shape[1]-1} steps\")\n",
        "\n",
        "print(\"\\nGenerating Othello data for analysis...\")\n",
        "obs_othello, actions_othello = generate_trajectories('othello', n_trajectories=500, max_steps=30, img_size=64)\n",
        "obs_othello_t = torch.from_numpy(obs_othello).to(device)\n",
        "actions_othello_t = torch.from_numpy(actions_othello).to(device)\n",
        "print(f\"  Othello: {obs_othello.shape[0]} trajectories, {obs_othello.shape[1]-1} steps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_and_analyze_2048"
      },
      "outputs": [],
      "source": [
        "# Train and analyze 2048 model\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING AND ANALYZING 2048 MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create and train model\n",
        "cfg_2048 = VQWorldModelConfig(\n",
        "    img_size=64,\n",
        "    n_actions=4,\n",
        "    codebook_size=512,\n",
        "    code_dim=64,\n",
        "    ema_decay=0.95,\n",
        "    reset_threshold=2,\n",
        "    reset_every=100,\n",
        ")\n",
        "model_2048 = VQWorldModel(cfg_2048).to(device)\n",
        "optimizer = torch.optim.AdamW(model_2048.parameters(), lr=3e-4)\n",
        "\n",
        "# Training\n",
        "model_2048.train()\n",
        "train_steps = 15000\n",
        "\n",
        "pbar = tqdm(range(1, train_steps + 1), desc=\"Training 2048\")\n",
        "for step in pbar:\n",
        "    idx = torch.randint(0, obs_2048_t.shape[0], (32,))\n",
        "    obs_batch = obs_2048_t[idx]\n",
        "    action_batch = actions_2048_t[idx]\n",
        "    \n",
        "    losses = model_2048.compute_loss(obs_batch, action_batch, unroll_steps=5)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    losses['total_loss'].backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model_2048.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    \n",
        "    if step % 500 == 0:\n",
        "        pbar.set_postfix({\n",
        "            'loss': f\"{losses['total_loss'].item():.3f}\",\n",
        "            'ent': f\"{losses['entropy'].item():.2f}\",\n",
        "            'codes': f\"{losses['unique_codes']}\",\n",
        "        })\n",
        "\n",
        "print(\"\\nTraining complete. Running rule extraction...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_2048"
      },
      "outputs": [],
      "source": [
        "# Analyze 2048 model\n",
        "os.makedirs(f\"{OUT_DIR}/rule_analysis_2048\", exist_ok=True)\n",
        "\n",
        "extractor_2048 = analyze_model(\n",
        "    model_2048,\n",
        "    obs_2048_t,\n",
        "    actions_2048_t,\n",
        "    device,\n",
        "    game_name='2048',\n",
        "    save_dir=f\"{OUT_DIR}/rule_analysis_2048\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_and_analyze_othello"
      },
      "outputs": [],
      "source": [
        "# Train and analyze Othello model\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING AND ANALYZING OTHELLO MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create and train model\n",
        "cfg_othello = VQWorldModelConfig(\n",
        "    img_size=64,\n",
        "    n_actions=64,\n",
        "    codebook_size=512,\n",
        "    code_dim=64,\n",
        "    ema_decay=0.95,\n",
        "    reset_threshold=2,\n",
        "    reset_every=100,\n",
        ")\n",
        "model_othello = VQWorldModel(cfg_othello).to(device)\n",
        "optimizer = torch.optim.AdamW(model_othello.parameters(), lr=3e-4)\n",
        "\n",
        "# Training\n",
        "model_othello.train()\n",
        "train_steps = 15000\n",
        "\n",
        "pbar = tqdm(range(1, train_steps + 1), desc=\"Training Othello\")\n",
        "for step in pbar:\n",
        "    idx = torch.randint(0, obs_othello_t.shape[0], (32,))\n",
        "    obs_batch = obs_othello_t[idx]\n",
        "    action_batch = actions_othello_t[idx]\n",
        "    \n",
        "    losses = model_othello.compute_loss(obs_batch, action_batch, unroll_steps=5)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    losses['total_loss'].backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model_othello.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    \n",
        "    if step % 500 == 0:\n",
        "        pbar.set_postfix({\n",
        "            'loss': f\"{losses['total_loss'].item():.3f}\",\n",
        "            'ent': f\"{losses['entropy'].item():.2f}\",\n",
        "            'codes': f\"{losses['unique_codes']}\",\n",
        "        })\n",
        "\n",
        "print(\"\\nTraining complete. Running rule extraction...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_othello"
      },
      "outputs": [],
      "source": [
        "# Analyze Othello model\n",
        "os.makedirs(f\"{OUT_DIR}/rule_analysis_othello\", exist_ok=True)\n",
        "\n",
        "extractor_othello = analyze_model(\n",
        "    model_othello,\n",
        "    obs_othello_t,\n",
        "    actions_othello_t,\n",
        "    device,\n",
        "    game_name='othello',\n",
        "    save_dir=f\"{OUT_DIR}/rule_analysis_othello\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_header"
      },
      "source": [
        "---\n",
        "## Side-by-Side Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison"
      },
      "outputs": [],
      "source": [
        "# Compare entropy distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 2048\n",
        "ax = axes[0]\n",
        "if extractor_2048.transition_entropy is not None:\n",
        "    ent_2048 = []\n",
        "    for code in range(cfg_2048.codebook_size):\n",
        "        for action in range(cfg_2048.n_actions):\n",
        "            count = extractor_2048.transition_counts[code, action].sum()\n",
        "            if count >= 5:\n",
        "                ent_2048.append(extractor_2048.transition_entropy[code, action])\n",
        "    ent_2048 = np.array(ent_2048)\n",
        "    \n",
        "    ax.hist(ent_2048, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    ax.axvline(x=0.1, color='r', linestyle='--', label='Deterministic threshold')\n",
        "    ax.set_xlabel('Entropy (bits)')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title(f'2048: {(ent_2048 < 0.1).sum()}/{len(ent_2048)} deterministic ({100*(ent_2048 < 0.1).mean():.1f}%)')\n",
        "    ax.legend()\n",
        "\n",
        "# Othello\n",
        "ax = axes[1]\n",
        "if extractor_othello.transition_entropy is not None:\n",
        "    ent_othello = []\n",
        "    for code in range(cfg_othello.codebook_size):\n",
        "        for action in range(cfg_othello.n_actions):\n",
        "            count = extractor_othello.transition_counts[code, action].sum()\n",
        "            if count >= 5:\n",
        "                ent_othello.append(extractor_othello.transition_entropy[code, action])\n",
        "    ent_othello = np.array(ent_othello)\n",
        "    \n",
        "    ax.hist(ent_othello, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
        "    ax.axvline(x=0.1, color='r', linestyle='--', label='Deterministic threshold')\n",
        "    ax.set_xlabel('Entropy (bits)')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title(f'Othello: {(ent_othello < 0.1).sum()}/{len(ent_othello)} deterministic ({100*(ent_othello < 0.1).mean():.1f}%)')\n",
        "    ax.legend()\n",
        "\n",
        "plt.suptitle('Entropy Distribution Comparison: Rules vs Chance', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUT_DIR}/entropy_comparison.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSaved comparison to: {OUT_DIR}/entropy_comparison.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_table"
      },
      "outputs": [],
      "source": [
        "# Summary table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY: LEARNED RULES VS CHANCE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Game':<15} {'Rules':<12} {'Chance':<12} {'% Rules':<12} {'Codebook':<15}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 2048\n",
        "n_rules_2048 = len([r for r in extractor_2048.rules if r.is_deterministic])\n",
        "n_chance_2048 = len([r for r in extractor_2048.rules if not r.is_deterministic])\n",
        "pct_2048 = 100 * n_rules_2048 / max(1, n_rules_2048 + n_chance_2048)\n",
        "codes_2048 = int((extractor_2048.codebook_usage > 0).sum()) if extractor_2048.codebook_usage is not None else 'N/A'\n",
        "print(f\"{'2048':<15} {n_rules_2048:<12} {n_chance_2048:<12} {pct_2048:<12.1f} {codes_2048}/{cfg_2048.codebook_size}\")\n",
        "\n",
        "# Othello\n",
        "n_rules_othello = len([r for r in extractor_othello.rules if r.is_deterministic])\n",
        "n_chance_othello = len([r for r in extractor_othello.rules if not r.is_deterministic])\n",
        "pct_othello = 100 * n_rules_othello / max(1, n_rules_othello + n_chance_othello)\n",
        "codes_othello = int((extractor_othello.codebook_usage > 0).sum()) if extractor_othello.codebook_usage is not None else 'N/A'\n",
        "print(f\"{'Othello':<15} {n_rules_othello:<12} {n_chance_othello:<12} {pct_othello:<12.1f} {codes_othello}/{cfg_othello.codebook_size}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION:\")\n",
        "print(\"-\"*70)\n",
        "print(\"• 2048 should have BOTH rules (slides) AND chance (tile spawns)\")\n",
        "print(\"• Othello should be ~100% rules (fully deterministic)\")\n",
        "print(\"• Higher codebook usage = richer representation\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "---\n",
        "## Next Steps\n",
        "\n",
        "If the experiments above show the expected patterns:\n",
        "- **2048**: Mix of rules and chance\n",
        "- **Othello**: Nearly 100% rules\n",
        "\n",
        "Then we're ready for:\n",
        "\n",
        "### 1. Planning Benchmark (VQ-MCTS)\n",
        "- Implement tree search that only branches on high-entropy transitions\n",
        "- Compare tree size vs standard MCTS\n",
        "\n",
        "### 2. Transfer Experiment\n",
        "- Train on 2048 variant A (one visual style)\n",
        "- Fine-tune encoder only on variant B (different style)\n",
        "- Test if dynamics transfer (they should!)\n",
        "\n",
        "### 3. Connect to TG-SMN\n",
        "- Rules = stable structure, compress well\n",
        "- Randomness = noise, don't memorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_models"
      },
      "outputs": [],
      "source": [
        "# Save trained models for later use\n",
        "torch.save({\n",
        "    'model_state': model_2048.state_dict(),\n",
        "    'config': cfg_2048,\n",
        "}, f'{OUT_DIR}/model_2048.pt')\n",
        "\n",
        "torch.save({\n",
        "    'model_state': model_othello.state_dict(),\n",
        "    'config': cfg_othello,\n",
        "}, f'{OUT_DIR}/model_othello.pt')\n",
        "\n",
        "print(f\"Models saved to {OUT_DIR}/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
