{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# VQ-VAE World Model: Learning Rules from Pixels\n",
        "\n",
        "This notebook runs the VQ-VAE world model experiments that learn to:\n",
        "1. **Distinguish deterministic rules from stochastic chance** (without being told!)\n",
        "2. **Extract interpretable rules** from the learned representations\n",
        "\n",
        "## Key Insight\n",
        "\n",
        "VQ-VAE with categorical transition predictions = **entropy learned from data**:\n",
        "- Same (code, action) → same next_code consistently = **RULE** (low entropy)\n",
        "- Same (code, action) → varied next_codes = **CHANCE** (high entropy)\n",
        "\n",
        "## Experiments\n",
        "\n",
        "1. **2048**: Should show ~14x higher entropy for positions that change (stochastic tile spawns)\n",
        "2. **Othello**: Should show near-zero entropy everywhere (fully deterministic)\n",
        "3. **Rule Extraction**: Visualize what the model learned as interpretable rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gpu_check",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f4f0f6-6af1-421a-e2b5-ef1e090bcfae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-20dcf7d3-3b88-6496-4498-fda958ad0429)\n",
            "PyTorch 2.9.0+cu126, CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi -L || echo 'No GPU detected'\n",
        "import torch\n",
        "print(f'PyTorch {torch.__version__}, CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mount_drive",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c29d9a-d839-457e-9d8f-b16602124764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Cloning into 'tg_smn'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (226/226), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 226 (delta 93), reused 182 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (226/226), 243.21 KiB | 780.00 KiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "/content/tg_smn\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive for outputs only\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone repo to ephemeral /content (NOT Drive!)\n",
        "%cd /content\n",
        "if os.path.exists('/content/tg_smn'):\n",
        "    %cd /content/tg_smn\n",
        "    !git fetch origin\n",
        "    !git reset --hard origin/main  # Always match remote\n",
        "else:\n",
        "    !git clone https://github.com/RespectableGlioma/tg_smn.git\n",
        "    %cd /content/tg_smn\n",
        "\n",
        "# Add to Python path\n",
        "import sys\n",
        "sys.path.insert(0, '/content/tg_smn')\n",
        "\n",
        "# Define output directory on Drive (outputs only!)\n",
        "OUT_DIR = '/content/drive/MyDrive/Colab_Notebooks/tg_smn_outputs'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "REPO_DIR = '/content/tg_smn'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q tqdm numpy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment1_header"
      },
      "source": [
        "---\n",
        "## Experiment 1: 2048 (Stochastic Game)\n",
        "\n",
        "2048 has:\n",
        "- **Deterministic** slide/merge mechanics (THE RULES)\n",
        "- **Stochastic** tile spawns (THE CHANCE)\n",
        "\n",
        "The model should learn BOTH - showing bimodal entropy distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "train_2048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ad63dc-16bb-428f-9f3b-fcba1d4dbb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tg_smn\n",
            "\n",
            "============================================================\n",
            "VQ-VAE World Model v2 Training\n",
            "Game: 2048 | Steps: 20000 | Device: cuda\n",
            "============================================================\n",
            "\n",
            "Generating trajectories...\n",
            "Generating 2048: 100% 2000/2000 [00:21<00:00, 93.29it/s] \n",
            "Data: 2000 trajectories, 50 steps each\n",
            "Obs shape: (2000, 51, 1, 64, 64), Actions shape: (2000, 50)\n",
            "\n",
            "Model parameters: 1,710,401\n",
            "  1% 263/20000 [00:39<49:37,  6.63it/s, loss=2.7037, recon=0.0065, trans=2.6968, ent=6.673, codes=32.0/512]\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/tg_smn/world_models/stoch_muzero/train_vq_v2.py\", line 410, in <module>\n",
            "    main()\n",
            "  File \"/content/tg_smn/world_models/stoch_muzero/train_vq_v2.py\", line 396, in main\n",
            "    train(\n",
            "  File \"/content/tg_smn/world_models/stoch_muzero/train_vq_v2.py\", line 303, in train\n",
            "    losses['total_loss'].backward()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 625, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 841, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 206.12 MiB is free. Process 6494 has 14.54 GiB memory in use. Of the allocated memory 13.63 GiB is allocated by PyTorch, and 793.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ],
      "source": [
        "# Train VQ World Model on 2048\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "!python -m world_models.stoch_muzero.train_vq_v2 \\\n",
        "    --game 2048 \\\n",
        "    --train_steps 20000 \\\n",
        "    --batch_size 32 \\\n",
        "    --codebook_size 512 \\\n",
        "    --n_trajectories 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment2_header"
      },
      "source": [
        "---\n",
        "## Experiment 2: Othello (Deterministic Game)\n",
        "\n",
        "Othello has:\n",
        "- **Only deterministic** transitions\n",
        "- No randomness at all\n",
        "\n",
        "The model should show near-zero entropy EVERYWHERE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_othello",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54ee77c-39ca-41eb-be84-d1d266a7deab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tg_smn\n",
            "\n",
            "============================================================\n",
            "VQ-VAE World Model v2 Training\n",
            "Game: othello | Steps: 20000 | Device: cuda\n",
            "============================================================\n",
            "\n",
            "Generating trajectories...\n",
            "Generating Othello:  74% 1481/2000 [00:47<00:13, 37.48it/s]"
          ]
        }
      ],
      "source": [
        "# Train VQ World Model on Othello\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "!python -m world_models.stoch_muzero.train_vq_v2 \\\n",
        "    --game othello \\\n",
        "    --train_steps 20000 \\\n",
        "    --batch_size 32 \\\n",
        "    --codebook_size 512 \\\n",
        "    --n_trajectories 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rule_extraction_header"
      },
      "source": [
        "---\n",
        "## Rule Extraction & Visualization\n",
        "\n",
        "Now we extract and visualize what the models learned:\n",
        "1. **Codebook Gallery**: What does each discrete code represent?\n",
        "2. **Entropy Distribution**: How many rules vs chance transitions?\n",
        "3. **Transition Graph**: Visual map of the learned dynamics\n",
        "4. **Rule Summary**: List of discovered deterministic rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rule_extraction_setup"
      },
      "outputs": [],
      "source": [
        "# Setup for rule extraction\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import our modules\n",
        "import sys\n",
        "sys.path.insert(0, REPO_DIR)\n",
        "\n",
        "from world_models.stoch_muzero.vq_model_v2 import VQWorldModel, VQWorldModelConfig\n",
        "from world_models.stoch_muzero.rule_extraction import RuleExtractor, analyze_model\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_data_for_analysis"
      },
      "outputs": [],
      "source": [
        "# Generate fresh data for analysis\n",
        "from world_models.stoch_muzero.train_vq_v2 import generate_trajectories\n",
        "\n",
        "print(\"Generating 2048 data for analysis...\")\n",
        "obs_2048, actions_2048 = generate_trajectories('2048', n_trajectories=500, max_steps=30, img_size=64)\n",
        "obs_2048_t = torch.from_numpy(obs_2048).to(device)\n",
        "actions_2048_t = torch.from_numpy(actions_2048).to(device)\n",
        "print(f\"  2048: {obs_2048.shape[0]} trajectories, {obs_2048.shape[1]-1} steps\")\n",
        "\n",
        "print(\"\\nGenerating Othello data for analysis...\")\n",
        "obs_othello, actions_othello = generate_trajectories('othello', n_trajectories=500, max_steps=30, img_size=64)\n",
        "obs_othello_t = torch.from_numpy(obs_othello).to(device)\n",
        "actions_othello_t = torch.from_numpy(actions_othello).to(device)\n",
        "print(f\"  Othello: {obs_othello.shape[0]} trajectories, {obs_othello.shape[1]-1} steps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_and_analyze_2048"
      },
      "outputs": [],
      "source": [
        "# Train and analyze 2048 model\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING AND ANALYZING 2048 MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create and train model\n",
        "cfg_2048 = VQWorldModelConfig(\n",
        "    img_size=64,\n",
        "    n_actions=4,\n",
        "    codebook_size=512,\n",
        "    code_dim=64,\n",
        "    ema_decay=0.95,\n",
        "    reset_threshold=2,\n",
        "    reset_every=100,\n",
        ")\n",
        "model_2048 = VQWorldModel(cfg_2048).to(device)\n",
        "optimizer = torch.optim.AdamW(model_2048.parameters(), lr=3e-4)\n",
        "\n",
        "# Training\n",
        "model_2048.train()\n",
        "train_steps = 15000\n",
        "\n",
        "pbar = tqdm(range(1, train_steps + 1), desc=\"Training 2048\")\n",
        "for step in pbar:\n",
        "    idx = torch.randint(0, obs_2048_t.shape[0], (32,))\n",
        "    obs_batch = obs_2048_t[idx]\n",
        "    action_batch = actions_2048_t[idx]\n",
        "\n",
        "    losses = model_2048.compute_loss(obs_batch, action_batch, unroll_steps=5)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses['total_loss'].backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model_2048.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 500 == 0:\n",
        "        pbar.set_postfix({\n",
        "            'loss': f\"{losses['total_loss'].item():.3f}\",\n",
        "            'ent': f\"{losses['entropy'].item():.2f}\",\n",
        "            'codes': f\"{losses['unique_codes']}\",\n",
        "        })\n",
        "\n",
        "print(\"\\nTraining complete. Running rule extraction...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_2048"
      },
      "outputs": [],
      "source": [
        "# Analyze 2048 model\n",
        "os.makedirs(f\"{OUT_DIR}/rule_analysis_2048\", exist_ok=True)\n",
        "\n",
        "extractor_2048 = analyze_model(\n",
        "    model_2048,\n",
        "    obs_2048_t,\n",
        "    actions_2048_t,\n",
        "    device,\n",
        "    game_name='2048',\n",
        "    save_dir=f\"{OUT_DIR}/rule_analysis_2048\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_and_analyze_othello"
      },
      "outputs": [],
      "source": [
        "# Train and analyze Othello model\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING AND ANALYZING OTHELLO MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create and train model\n",
        "cfg_othello = VQWorldModelConfig(\n",
        "    img_size=64,\n",
        "    n_actions=64,\n",
        "    codebook_size=512,\n",
        "    code_dim=64,\n",
        "    ema_decay=0.95,\n",
        "    reset_threshold=2,\n",
        "    reset_every=100,\n",
        ")\n",
        "model_othello = VQWorldModel(cfg_othello).to(device)\n",
        "optimizer = torch.optim.AdamW(model_othello.parameters(), lr=3e-4)\n",
        "\n",
        "# Training\n",
        "model_othello.train()\n",
        "train_steps = 15000\n",
        "\n",
        "pbar = tqdm(range(1, train_steps + 1), desc=\"Training Othello\")\n",
        "for step in pbar:\n",
        "    idx = torch.randint(0, obs_othello_t.shape[0], (32,))\n",
        "    obs_batch = obs_othello_t[idx]\n",
        "    action_batch = actions_othello_t[idx]\n",
        "\n",
        "    losses = model_othello.compute_loss(obs_batch, action_batch, unroll_steps=5)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses['total_loss'].backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model_othello.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 500 == 0:\n",
        "        pbar.set_postfix({\n",
        "            'loss': f\"{losses['total_loss'].item():.3f}\",\n",
        "            'ent': f\"{losses['entropy'].item():.2f}\",\n",
        "            'codes': f\"{losses['unique_codes']}\",\n",
        "        })\n",
        "\n",
        "print(\"\\nTraining complete. Running rule extraction...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_othello"
      },
      "outputs": [],
      "source": [
        "# Analyze Othello model\n",
        "os.makedirs(f\"{OUT_DIR}/rule_analysis_othello\", exist_ok=True)\n",
        "\n",
        "extractor_othello = analyze_model(\n",
        "    model_othello,\n",
        "    obs_othello_t,\n",
        "    actions_othello_t,\n",
        "    device,\n",
        "    game_name='othello',\n",
        "    save_dir=f\"{OUT_DIR}/rule_analysis_othello\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_header"
      },
      "source": [
        "---\n",
        "## Side-by-Side Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison"
      },
      "outputs": [],
      "source": [
        "# Compare entropy distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 2048\n",
        "ax = axes[0]\n",
        "if extractor_2048.transition_entropy is not None:\n",
        "    ent_2048 = []\n",
        "    for code in range(cfg_2048.codebook_size):\n",
        "        for action in range(cfg_2048.n_actions):\n",
        "            count = extractor_2048.transition_counts[code, action].sum()\n",
        "            if count >= 5:\n",
        "                ent_2048.append(extractor_2048.transition_entropy[code, action])\n",
        "    ent_2048 = np.array(ent_2048)\n",
        "\n",
        "    ax.hist(ent_2048, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    ax.axvline(x=0.1, color='r', linestyle='--', label='Deterministic threshold')\n",
        "    ax.set_xlabel('Entropy (bits)')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title(f'2048: {(ent_2048 < 0.1).sum()}/{len(ent_2048)} deterministic ({100*(ent_2048 < 0.1).mean():.1f}%)')\n",
        "    ax.legend()\n",
        "\n",
        "# Othello\n",
        "ax = axes[1]\n",
        "if extractor_othello.transition_entropy is not None:\n",
        "    ent_othello = []\n",
        "    for code in range(cfg_othello.codebook_size):\n",
        "        for action in range(cfg_othello.n_actions):\n",
        "            count = extractor_othello.transition_counts[code, action].sum()\n",
        "            if count >= 5:\n",
        "                ent_othello.append(extractor_othello.transition_entropy[code, action])\n",
        "    ent_othello = np.array(ent_othello)\n",
        "\n",
        "    ax.hist(ent_othello, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
        "    ax.axvline(x=0.1, color='r', linestyle='--', label='Deterministic threshold')\n",
        "    ax.set_xlabel('Entropy (bits)')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title(f'Othello: {(ent_othello < 0.1).sum()}/{len(ent_othello)} deterministic ({100*(ent_othello < 0.1).mean():.1f}%)')\n",
        "    ax.legend()\n",
        "\n",
        "plt.suptitle('Entropy Distribution Comparison: Rules vs Chance', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUT_DIR}/entropy_comparison.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSaved comparison to: {OUT_DIR}/entropy_comparison.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_table"
      },
      "outputs": [],
      "source": [
        "# Summary table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY: LEARNED RULES VS CHANCE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Game':<15} {'Rules':<12} {'Chance':<12} {'% Rules':<12} {'Codebook':<15}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 2048\n",
        "n_rules_2048 = len([r for r in extractor_2048.rules if r.is_deterministic])\n",
        "n_chance_2048 = len([r for r in extractor_2048.rules if not r.is_deterministic])\n",
        "pct_2048 = 100 * n_rules_2048 / max(1, n_rules_2048 + n_chance_2048)\n",
        "codes_2048 = int((extractor_2048.codebook_usage > 0).sum()) if extractor_2048.codebook_usage is not None else 'N/A'\n",
        "print(f\"{'2048':<15} {n_rules_2048:<12} {n_chance_2048:<12} {pct_2048:<12.1f} {codes_2048}/{cfg_2048.codebook_size}\")\n",
        "\n",
        "# Othello\n",
        "n_rules_othello = len([r for r in extractor_othello.rules if r.is_deterministic])\n",
        "n_chance_othello = len([r for r in extractor_othello.rules if not r.is_deterministic])\n",
        "pct_othello = 100 * n_rules_othello / max(1, n_rules_othello + n_chance_othello)\n",
        "codes_othello = int((extractor_othello.codebook_usage > 0).sum()) if extractor_othello.codebook_usage is not None else 'N/A'\n",
        "print(f\"{'Othello':<15} {n_rules_othello:<12} {n_chance_othello:<12} {pct_othello:<12.1f} {codes_othello}/{cfg_othello.codebook_size}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION:\")\n",
        "print(\"-\"*70)\n",
        "print(\"• 2048 should have BOTH rules (slides) AND chance (tile spawns)\")\n",
        "print(\"• Othello should be ~100% rules (fully deterministic)\")\n",
        "print(\"• Higher codebook usage = richer representation\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "---\n",
        "## Next Steps\n",
        "\n",
        "If the experiments above show the expected patterns:\n",
        "- **2048**: Mix of rules and chance\n",
        "- **Othello**: Nearly 100% rules\n",
        "\n",
        "Then we're ready for:\n",
        "\n",
        "### 1. Planning Benchmark (VQ-MCTS)\n",
        "- Implement tree search that only branches on high-entropy transitions\n",
        "- Compare tree size vs standard MCTS\n",
        "\n",
        "### 2. Transfer Experiment\n",
        "- Train on 2048 variant A (one visual style)\n",
        "- Fine-tune encoder only on variant B (different style)\n",
        "- Test if dynamics transfer (they should!)\n",
        "\n",
        "### 3. Connect to TG-SMN\n",
        "- Rules = stable structure, compress well\n",
        "- Randomness = noise, don't memorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_models"
      },
      "outputs": [],
      "source": [
        "# Save trained models for later use\n",
        "torch.save({\n",
        "    'model_state': model_2048.state_dict(),\n",
        "    'config': cfg_2048,\n",
        "}, f'{OUT_DIR}/model_2048.pt')\n",
        "\n",
        "torch.save({\n",
        "    'model_state': model_othello.state_dict(),\n",
        "    'config': cfg_othello,\n",
        "}, f'{OUT_DIR}/model_othello.pt')\n",
        "\n",
        "print(f\"Models saved to {OUT_DIR}/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byLLQEIGXa0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}